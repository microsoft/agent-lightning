# =============================================================================
# UI Configuration (for debugging/testing)
# =============================================================================

# WebShop Server Configuration
# URL of the Python Flask WebShop server
WEBSHOP_URL=http://localhost:3000

# =============================================================================
# Model Serving Configuration
# =============================================================================
#
# There are two ways to configure model serving:
#
# OPTION 1: VERL-Integrated (Recommended for Training)
# -----------------------------------------------------
# When running training with VERL (python agl/run_training.py qwen):
# - VERL automatically starts vLLM with the Qwen model
# - VERL starts the LLM Proxy and publishes it to the Store
# - The headless runner fetches the LLM endpoint from the Store
# - Leave OPENAI_API_BASE unset; the runner discovers it automatically
#
# OPTION 2: Manual/External Endpoint
# -----------------------------------
# For development, debugging, or using external APIs:
# - Set OPENAI_API_BASE to your endpoint (OpenAI, local vLLM, etc.)
# - Set WEBSHOP_MODEL to the model ID
# - This is also useful for UI-only testing without the training loop
#
# API key for OpenAI or compatible service (use 'dummy' for local vLLM)
OPENAI_API_KEY=sk-xxx

# Base URL for OpenAI-compatible endpoint (vLLM, LLMProxy, etc.)
# Leave unset when using VERL-integrated training (auto-discovered from Store)
# Set explicitly for manual/external endpoint usage
# OPENAI_API_BASE=http://localhost:8000/v1

# Model ID to use for the WebShop agent
# When using VERL-integrated training, this is overridden by the Store resource
WEBSHOP_MODEL=gpt-4o-mini

# =============================================================================
# Headless Runner Configuration (for training)
# These variables are ONLY used by scripts/headless-runner.ts
# The UI operates in standalone demo mode and ignores these settings.
# =============================================================================

# Agent Lightning Store URL (required for training)
AGENT_LIGHTNING_STORE_URL=http://localhost:4747

# OTLP endpoint for OpenTelemetry traces
# Auto-derived from STORE_URL as /v1/traces if not set
# AGENT_LIGHTNING_OTLP_ENDPOINT=http://localhost:4747/v1/traces

# Mode for rollouts: train, val, or test
AGENT_LIGHTNING_MODE=train

# Service name for OpenTelemetry traces
AGENT_LIGHTNING_SERVICE_NAME=webshop-headless-runner

# Debugging
# Enable OpenTelemetry diagnostics logging
# OTEL_DIAG_LOG_LEVEL=DEBUG
