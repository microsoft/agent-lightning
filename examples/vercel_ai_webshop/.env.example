# Docker Compose Environment Variables
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# =============================================================================
# LLM Configuration
# =============================================================================
#
# Dev Mode (make dev):
#   - CPU-only, uses OPENAI_API_BASE for LLM inference
#   - Set OPENAI_API_KEY and optionally OPENAI_API_BASE
#   - If OPENAI_API_BASE is not set, uses OpenAI's default endpoint
#
# GPU Mode (make train):
#   - Uses VERL which internally manages vLLM
#   - VERL publishes the LLM endpoint to the Store
#   - Runners automatically discover the endpoint (no config needed)
#   - OPENAI_API_KEY/BASE are ignored in GPU mode
#
# =============================================================================

# OpenAI API key (required for dev mode, ignored in GPU mode)
OPENAI_API_KEY=sk-xxx

# Custom OpenAI-compatible endpoint (optional for dev mode)
# Examples:
#   - OpenAI: leave empty (uses default)
#   - Local vLLM: http://localhost:8000/v1
#   - Azure OpenAI: https://your-resource.openai.azure.com
# OPENAI_API_BASE=

# Model ID for dev mode (ignored in GPU mode - VERL config controls model)
# Default: gpt-4o-mini
WEBSHOP_MODEL=gpt-4o-mini
