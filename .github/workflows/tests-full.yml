name: GPU Test
permissions:
  contents: read
on:
  schedule:
    # Every day at 5 AM UTC+8
    - cron: '0 21 * * *'

  workflow_dispatch:

jobs:
  tests-full:
    runs-on: [self-hosted, 1ES.Pool=agl-runner-gpu]
    timeout-minutes: 30
    strategy:
      matrix:
        setup: [stable, latest]
      fail-fast: false
    steps:
      - name: Check GPU status
        run: nvidia-smi
      - uses: actions/checkout@v4
      - name: Create a virtual environment
        run: python3 -m venv .venv
      - name: Install dependencies (${{ matrix.setup }})
        run: |
          . .venv/bin/activate
          ./scripts/setup_${{ matrix.setup }}_gpu.sh
      - name: Freeze dependencies
        run: |
          . .venv/bin/activate
          which python
          which pip
          which uvx
          pip list | tee requirements-freeze.txt
      - name: Upload dependencies artifact
        uses: actions/upload-artifact@v4
        with:
          name: dependencies-${{ matrix.setup }}
          path: requirements-freeze.txt
          compression-level: 0

      - name: Launch LiteLLM Proxy
        run: |
          set -ex
          . .venv/bin/activate
          litellm --config scripts/litellm_ci.yaml --port 12306 &
          sleep 10  # Wait for the proxy to be up
        env:
          AZURE_API_BASE: ${{ secrets.AZURE_API_BASE }}
          AZURE_API_KEY: ${{ secrets.AZURE_API_KEY }}
      - name: Verify LiteLLM Proxy
        run: |
          set -ex
          . .venv/bin/activate
          python scripts/litellm_sanity_check.py
        env:
          OPENAI_BASE_URL: http://localhost:12306/
          OPENAI_API_KEY: dummy

      - name: Run tests
        run: |
          set -ex
          . .venv/bin/activate
          pytest -v --durations=0 tests
        env:
          PYTEST_ADDOPTS: "--color=yes"
          OPENAI_BASE_URL: http://localhost:12306/
          OPENAI_API_KEY: dummy
